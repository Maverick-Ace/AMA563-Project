{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchviz import make_dot\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import shap\n",
    "\n",
    "# 过滤警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_MODEL(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, edge_features_dim, drop_rate=0.5, inner_weights=None, outer_weights=None):\n",
    "        super(GAT_MODEL, self).__init__()\n",
    "        self.inner_weights = inner_weights\n",
    "        self.outer_weights = outer_weights\n",
    "\n",
    "        # Linear层\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # GAT层\n",
    "        self.conv1 = nn.ModuleList([GATConv(\n",
    "            -1, \n",
    "            hidden_size, \n",
    "            heads=8, \n",
    "            dropout=drop_rate,\n",
    "            concat=True,\n",
    "            negative_slope=0.2,\n",
    "            add_self_loops=True,\n",
    "            edge_dim=edge_features_dim,\n",
    "            bias=True,\n",
    "            residual=True) for _ in range(6)])\n",
    "      \n",
    "        self.conv_out = GATConv(\n",
    "            hidden_size*8, \n",
    "            output_size, \n",
    "            heads=1, \n",
    "            dropout=0.2,\n",
    "            concat=False,\n",
    "            negative_slope=0.2,\n",
    "            add_self_loops=True,\n",
    "            edge_dim=edge_features_dim,\n",
    "            bias=True,\n",
    "            residual=True)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, edge_weight, batch):\n",
    "        # 去除特殊值填充\n",
    "        maskx = (x != 1000).float()\n",
    "        x = x * maskx\n",
    "        maske = (edge_attr != 1000).float()\n",
    "        edge_attr = edge_attr * maske\n",
    "\n",
    "        # # 对edge_attr进行加权，每一个权重值乘以一行特征(pls r2作为权重计算指标)\n",
    "        # edge_attr = edge_attr * edge_weight.view(-1, 1)\n",
    "\n",
    "        # # 对x进行加权，元素对应相乘（pls模型的权重）\n",
    "        # x = x.reshape(-1, 8, x.shape[1])\n",
    "        # x = torch.cat([x[i, :, :] * self.inner_weights for i in range(x.shape[0])], dim=0)\n",
    "\n",
    "        # # 对edge_attr进行加权，元素对应相乘（pls模型的权重）\n",
    "        # edge_attr = edge_attr.reshape(-1, 56, edge_attr.shape[1])\n",
    "        # edge_attr = torch.cat([edge_attr[i, :, :] * self.outer_weights for i in range(edge_attr.shape[0])], dim=0)\n",
    "\n",
    "        # GAT层\n",
    "        for conv in self.conv1:\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv_out(x, edge_index, edge_attr)\n",
    "        \n",
    "        # print(x.shape)\n",
    "        # print(batch, batch.shape)\n",
    "        # assert False\n",
    "        x = x.reshape(-1, 8)\n",
    "        # print(x.shape)\n",
    "        # 沿第二个维度平均池化\n",
    "        x = torch.mean(x, dim=1, keepdim=True)\n",
    "        # print(x.shape)\n",
    "        assert x.shape[1] == 1\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, target):\n",
    "        target = torch.tensor(np.array(target), dtype=torch.float32)\n",
    "        # print(output.shape, target.shape)\n",
    "        \n",
    "        output = output.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "        loss = F.mse_loss(output, target)\n",
    "        # print(output, target)\n",
    "        # print(loss)\n",
    "        # assert False\n",
    "        return loss\n",
    "    \n",
    "# 创建模型实例\n",
    "model = GAT_MODEL(\n",
    "    input_size=4005, \n",
    "    hidden_size=32, \n",
    "    output_size=1,\n",
    "    edge_features_dim=4500)\n",
    "\n",
    "# 保存模型参数\n",
    "torch.save(model.state_dict(), 'template_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型参数\n",
    "# 加载权重'models/92_best_best.pth'\n",
    "model_path = 'models/92_best_best.pth'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "# 读取测试数据\n",
    "# 测试数据路径'dataset/test_dataset.pt'\n",
    "test_data_path = 'dataset/test_dataset.pt'\n",
    "test_data = torch.load(test_data_path)\n",
    "\n",
    "# dataloader\n",
    "test_loader = DataLoader(\n",
    "    GraphDataset(test_data),\n",
    "    batch_size=1,\n",
    "    shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # 计算梯度\n",
    "# model.eval()\n",
    "# for data in test_loader:\n",
    "#     data = data.to(device)\n",
    "#     out = model(data.x, data.edge_index, data.edge_attr, data.edge_weight, data.batch)\n",
    "#     y = model.loss(out, data.y)\n",
    "#     y.backward(retain_graph=True)\n",
    "#     break\n",
    "\n",
    "# # 使用 torchviz 生成计算图，并显示梯度数值\n",
    "# dot = make_dot(y, params=dict(model.named_parameters()), show_attrs=False, show_saved=True)\n",
    "# dot.format = 'png'\n",
    "# dot.attr(dpi='300') \n",
    "# dot.render('model92计算图')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [56] at index 0 does not match the shape of the indexed tensor [2800, 4500] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m ig \u001b[38;5;241m=\u001b[39m IntegratedGradients(model_predict)\n\u001b[0;32m     29\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m((test_data\u001b[38;5;241m.\u001b[39mx, test_data\u001b[38;5;241m.\u001b[39medge_index, test_data\u001b[38;5;241m.\u001b[39medge_attr, test_data\u001b[38;5;241m.\u001b[39mbatch))\n\u001b[1;32m---> 30\u001b[0m attributions, delta \u001b[38;5;241m=\u001b[39m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 可视化特征重要性\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[0;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    276\u001b[0m         num_examples,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[0;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[0;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[0;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[0;32m    364\u001b[0m ]\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\captum\\_utils\\gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[1;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\captum\\_utils\\common.py:531\u001b[0m, in \u001b[0;36m_run_forward\u001b[1;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[0;32m    528\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[0;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m--> 531\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _select_targets(output, target)\n",
      "Cell \u001b[1;32mIn[39], line 24\u001b[0m, in \u001b[0;36mmodel_predict\u001b[1;34m(data1, data2, data3, data4)\u001b[0m\n\u001b[0;32m     21\u001b[0m data4 \u001b[38;5;241m=\u001b[39m data4\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 24\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 56\u001b[0m, in \u001b[0;36mGAT_MODEL.forward\u001b[1;34m(self, x, edge_index, edge_attr, edge_weight, batch)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# # 对edge_attr进行加权，每一个权重值乘以一行特征(pls r2作为权重计算指标)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# edge_attr = edge_attr * edge_weight.view(-1, 1)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# GAT层\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1:\n\u001b[1;32m---> 56\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(x)\n\u001b[0;32m     58\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:347\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    345\u001b[0m         num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(num_nodes, x_dst\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    346\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size) \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_nodes\n\u001b[1;32m--> 347\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mremove_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m add_self_loops(\n\u001b[0;32m    350\u001b[0m         edge_index, edge_attr, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value,\n\u001b[0;32m    351\u001b[0m         num_nodes\u001b[38;5;241m=\u001b[39mnum_nodes)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n",
      "File \u001b[1;32md:\\BrainC\\brainc_env\\lib\\site-packages\\torch_geometric\\utils\\loop.py:131\u001b[0m, in \u001b[0;36mremove_self_loops\u001b[1;34m(edge_index, edge_attr)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, \u001b[43medge_attr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: The shape of the mask [56] at index 0 does not match the shape of the indexed tensor [2800, 4500] at index 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# 假设 model 是你的 GAT 模型实例，test_loader 是你的测试数据加载器\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 获取测试数据\n",
    "for data in test_loader:\n",
    "    test_data = data\n",
    "    break\n",
    "\n",
    "# 定义一个函数来预测模型输出\n",
    "def model_predict(data1, data2, data3, data4):\n",
    "    print('1')\n",
    "    data1 = data1.to(device)\n",
    "    data2 = data2.to(device)\n",
    "    data3 = data3.to(device)\n",
    "    data4 = data4.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(data1, data2, data3, None, data4)\n",
    "    return out\n",
    "\n",
    "# 使用 Integrated Gradients 计算特征重要性\n",
    "ig = IntegratedGradients(model_predict)\n",
    "X = tuple((test_data.x, test_data.edge_index, test_data.edge_attr, test_data.batch))\n",
    "attributions, delta = ig.attribute(X, target=0, return_convergence_delta=True)\n",
    "\n",
    "# 可视化特征重要性\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 将 attributions 转换为 numpy 数组\n",
    "attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "# 绘制特征重要性图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(attributions.shape[1]), np.mean(np.abs(attributions), axis=0))\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance using Integrated Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_MODEL(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, edge_features_dim, drop_rate=0.5, inner_weights=None, outer_weights=None):\n",
    "        super(GAT_MODEL, self).__init__()\n",
    "        self.inner_weights = inner_weights\n",
    "        self.outer_weights = outer_weights\n",
    "\n",
    "        # GAT层\n",
    "        self.conv1 = GATConv(\n",
    "            -1, \n",
    "            hidden_size, \n",
    "            heads=8, \n",
    "            dropout=drop_rate,\n",
    "            concat=True,\n",
    "            negative_slope=0.2,\n",
    "            add_self_loops=True,\n",
    "            edge_dim=edge_features_dim,\n",
    "            bias=True,\n",
    "            residual=True)\n",
    "        \n",
    "        self.conv2 = GATConv(\n",
    "            -1, \n",
    "            hidden_size, \n",
    "            heads=8, \n",
    "            dropout=drop_rate,\n",
    "            concat=True,\n",
    "            negative_slope=0.2,\n",
    "            add_self_loops=True,\n",
    "            edge_dim=edge_features_dim,\n",
    "            bias=True,\n",
    "            residual=True)\n",
    "        \n",
    "        self.conv3 = GATConv(\n",
    "            -1, \n",
    "            hidden_size, \n",
    "            heads=8, \n",
    "            dropout=drop_rate,\n",
    "            concat=True,\n",
    "            negative_slope=0.2,\n",
    "            add_self_loops=True,\n",
    "            edge_dim=edge_features_dim,\n",
    "            bias=True,\n",
    "            residual=True)\n",
    "        \n",
    "        self.conv4 = GATConv(\n",
    "            -1, \n",
    "            hidden_size, \n",
    "            heads=8, \n",
    "            dropout=drop_rate,\n",
    "            concat=True,\n",
    "            negative_slope=0.2,\n",
    "            add_self_loops=True,\n",
    "            edge_dim=edge_features_dim,\n",
    "            bias=True,\n",
    "            residual=True)\n",
    "        \n",
    "        self.conv5 = GATConv(\n",
    "            -1, \n",
    "            hidden_size, \n",
    "            heads=8, \n",
    "            dropout=drop_rate,\n",
    "            concat=True,\n",
    "            negative_slope=0.2,\n",
    "            add_self_loops=True,\n",
    "            edge_dim=edge_features_dim,\n",
    "            bias=True,\n",
    "            residual=True)\n",
    "        \n",
    "        self.conv6 = GATConv(\n",
    "            -1, \n",
    "            hidden_size, \n",
    "            heads=8, \n",
    "            dropout=drop_rate,\n",
    "            concat=True,\n",
    "            negative_slope=0.2,\n",
    "            add_self_loops=True,\n",
    "            edge_dim=edge_features_dim,\n",
    "            bias=True,\n",
    "            residual=True)\n",
    "        \n",
    "        self.conv_out = GATConv(\n",
    "            hidden_size*8, \n",
    "            output_size, \n",
    "            heads=1, \n",
    "            dropout=0.2,\n",
    "            concat=False,\n",
    "            negative_slope=0.2,\n",
    "            add_self_loops=True,\n",
    "            edge_dim=edge_features_dim,\n",
    "            bias=True,\n",
    "            residual=True)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, edge_weight, batch):\n",
    "        # 去除特殊值填充\n",
    "        maskx = (x != 1000).float()\n",
    "        x = x * maskx\n",
    "        maske = (edge_attr != 1000).float()\n",
    "        edge_attr = edge_attr * maske\n",
    "\n",
    "        # # 对edge_attr进行加权，每一个权重值乘以一行特征(pls r2作为权重计算指标)\n",
    "        # edge_attr = edge_attr * edge_weight.view(-1, 1)\n",
    "\n",
    "        # # 对x进行加权，元素对应相乘（pls模型的权重）\n",
    "        # x = x.reshape(-1, 8, x.shape[1])\n",
    "        # x = torch.cat([x[i, :, :] * self.inner_weights for i in range(x.shape[0])], dim=0)\n",
    "\n",
    "        # # 对edge_attr进行加权，元素对应相乘（pls模型的权重）\n",
    "        # edge_attr = edge_attr.reshape(-1, 56, edge_attr.shape[1])\n",
    "        # edge_attr = torch.cat([edge_attr[i, :, :] * self.outer_weights for i in range(edge_attr.shape[0])], dim=0)\n",
    "\n",
    "        # GAT层\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv5(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv6(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv_out(x, edge_index, edge_attr)\n",
    "        \n",
    "        # print(x.shape)\n",
    "        # print(batch, batch.shape)\n",
    "        # assert False\n",
    "        x = x.reshape(-1, 8)\n",
    "        # print(x.shape)\n",
    "        # 沿第二个维度平均池化\n",
    "        x = torch.mean(x, dim=1, keepdim=True)\n",
    "        # print(x.shape)\n",
    "        assert x.shape[1] == 1\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, target):\n",
    "        target = torch.tensor(np.array(target), dtype=torch.float32)\n",
    "        # print(output.shape, target.shape)\n",
    "        \n",
    "        output = output.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "        loss = F.mse_loss(output, target)\n",
    "        # print(output, target)\n",
    "        # print(loss)\n",
    "        # assert False\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'template_model.pth' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "\n",
    "# 使用 netron 可视化模型\n",
    "netron.start('template_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
